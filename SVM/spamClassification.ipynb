{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Email Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "# Import regular expressions to process emails\n",
    "import re\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "# will be used to load MATLAB mat datafile format\n",
    "from scipy.io import loadmat\n",
    "import utils\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processEmail(email_contents, verbose=True):\n",
    "    \"\"\"\n",
    "    Preprocesses the body of an email and returns a list of indices \n",
    "    of the words contained in the email.    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    email_contents : str\n",
    "        A string containing one email. \n",
    "    \n",
    "    verbose : bool\n",
    "        If True, print the resulting email after processing.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    word_indices : list\n",
    "        A list of integers containing the index of each word in the \n",
    "    \"\"\"\n",
    "    # Load Vocabulary\n",
    "    vocabList = utils.getVocabList()\n",
    "    word_indices = []\n",
    "    # Lower case\n",
    "    email_contents = email_contents.lower()\n",
    "    # Strip all HTML\n",
    "    # Looks for any expression that starts with < and ends with > and replace\n",
    "    # and does not have any < or > in the tag it with a space\n",
    "    email_contents =re.compile('<[^<>]+>').sub(' ', email_contents)\n",
    "    # Handle Numbers\n",
    "    # Look for one or more characters between 0-9\n",
    "    email_contents = re.compile('[0-9]+').sub(' number ', email_contents)\n",
    "    # Handle URLS\n",
    "    # Look for strings starting with http:// or https://\n",
    "    email_contents = re.compile('(http|https)://[^\\s]*').sub(' httpaddr ', email_contents)\n",
    "    # Handle Email Addresses\n",
    "    # Look for strings with @ in the middle\n",
    "    email_contents = re.compile('[^\\s]+@[^\\s]+').sub(' emailaddr ', email_contents)\n",
    "    # Handle $ sign\n",
    "    email_contents = re.compile('[$]+').sub(' dollar ', email_contents)\n",
    "    # get rid of any punctuation\n",
    "    email_contents = re.split('[ @$/#.-:&*+=\\[\\]?!(){},''\">_<;%\\n\\r]', email_contents)\n",
    "    # remove any empty word string\n",
    "    email_contents = [word for word in email_contents if len(word) > 0]\n",
    "    # Stem the email contents word by word\n",
    "    stemmer = utils.PorterStemmer()\n",
    "    processed_email = []\n",
    "    for word in email_contents:\n",
    "        # Remove any remaining non alphanumeric characters in word\n",
    "        word = re.compile('[^a-zA-Z0-9]').sub('', word).strip()\n",
    "        word = stemmer.stem(word)\n",
    "        processed_email.append(word)\n",
    "\n",
    "        if len(word) < 1:\n",
    "            continue\n",
    "\n",
    "        if word in vocabList:\n",
    "            word_indices.append(vocabList.index(word))\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print('----------------')\n",
    "        print('Processed email:')\n",
    "        print('----------------')\n",
    "        print(' '.join(processed_email))\n",
    "    return word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Processed email:\n",
      "----------------\n",
      "anyon know how much it cost to host a web portal well it depend on how mani visitor your expect thi can be anywher from less than number buck a month to a coupl of dollar number you should checkout httpaddr or perhap amazon ec number if your run someth big to unsubscrib yourself from thi mail list send an email to emailaddr\n",
      "-------------\n",
      "Word Indices:\n",
      "-------------\n",
      "[85, 915, 793, 1076, 882, 369, 1698, 789, 1821, 1830, 882, 430, 1170, 793, 1001, 1894, 591, 1675, 237, 161, 88, 687, 944, 1662, 1119, 1061, 1698, 374, 1161, 476, 1119, 1892, 1509, 798, 1181, 1236, 511, 1119, 809, 1894, 1439, 1546, 180, 1698, 1757, 1895, 687, 1675, 991, 960, 1476, 70, 529, 1698, 530]\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('Data', 'emailSample1.txt')) as fid:\n",
    "    file_contents = fid.read()\n",
    "\n",
    "word_indices  = processEmail(file_contents)\n",
    "\n",
    "#Print Stats\n",
    "print('-------------')\n",
    "print('Word Indices:')\n",
    "print('-------------')\n",
    "print(word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emailFeatures(word_indices):\n",
    "    \"\"\"\n",
    "    Takes in a word_indices vector and produces a feature vector from the word indices. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word_indices : list\n",
    "        A list of word indices from the vocabulary list.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x : list \n",
    "        The computed feature vector.\n",
    "    \"\"\"\n",
    "    # Total number of words in the dictionary\n",
    "    n = 1899\n",
    "    x = np.zeros(n)\n",
    "    for idx in word_indices:\n",
    "        x[idx] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Processed email:\n",
      "----------------\n",
      "anyon know how much it cost to host a web portal well it depend on how mani visitor your expect thi can be anywher from less than number buck a month to a coupl of dollar number you should checkout httpaddr or perhap amazon ec number if your run someth big to unsubscrib yourself from thi mail list send an email to emailaddr\n",
      "\n",
      "Length of feature vector: 1899\n",
      "Number of non-zero entries: 45\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('Data', 'emailSample1.txt')) as fid:\n",
    "    file_contents = fid.read()\n",
    "\n",
    "word_indices  = processEmail(file_contents)\n",
    "features      = emailFeatures(word_indices)\n",
    "\n",
    "# Print Stats\n",
    "print('\\nLength of feature vector: %d' % len(features))\n",
    "print('Number of non-zero entries: %d' % sum(features > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section we will load a preprocessed training dataset(from SpamAssassin Public Corpus) that will be used to train a SVM classifier. The file spamTrain.mat (within the Data folder for this exercise) contains 4000 training examples of spam and non-spam email, while spamTest.mat contains 1000 test examples. Each original email was processed using the processEmail and emailFeatures functions and converted into a vector  ùë•(ùëñ)‚àà‚Ñù1899 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, kernel='linear')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Spam Email dataset\n",
    "data = loadmat(os.path.join('Data', 'spamTrain.mat'))\n",
    "X, y= data['X'].astype(float), data['y'][:, 0]\n",
    "\n",
    "clf = svm.SVC(kernel='linear',C = 0.1) \n",
    "# fitting x samples and y classes \n",
    "clf.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 99.83\n"
     ]
    }
   ],
   "source": [
    "# Compute the training accuracy\n",
    "p = clf.predict(X)\n",
    "print('Training Accuracy: %.2f' % (np.mean(p == y) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the trained Linear SVM on a test set ...\n",
      "Test Accuracy: 98.90\n"
     ]
    }
   ],
   "source": [
    "# Load the test dataset\n",
    "data = loadmat(os.path.join('Data', 'spamTest.mat'))\n",
    "Xtest, ytest = data['Xtest'].astype(float), data['ytest'][:, 0]\n",
    "\n",
    "print('Evaluating the trained Linear SVM on a test set ...')\n",
    "p = clf.predict(Xtest)\n",
    "\n",
    "print('Test Accuracy: %.2f' % (np.mean(p == ytest) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top Predictors for Spam\n",
    "To better understand how the spam classifier works, we can inspect the parameters to see which words the classifier thinks are the most predictive of spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 words are the most likely indicators of spam :\n",
      "our\n",
      "click\n",
      "remov\n",
      "guarante\n",
      "visit\n",
      "basenumb\n",
      "dollar\n",
      "will\n",
      "price\n",
      "pleas\n",
      "most\n",
      "nbsp\n",
      "lo\n",
      "ga\n",
      "hour\n"
     ]
    }
   ],
   "source": [
    "vocabList = utils.getVocabList()\n",
    "arr = clf.coef_[0]\n",
    "top15 = arr.argsort()[-15:][::-1]\n",
    "print(\"15 words are the most likely indicators of spam :\")\n",
    "for ele in top15:\n",
    "    print(vocabList[ele])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
